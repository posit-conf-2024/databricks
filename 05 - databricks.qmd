---
title: "Databricks Connect"
---

## 01 - Connect to Databricks Connect cluster
*Copy a simple table into the Spark session*

```{r}
library(sparklyr)
library(dplyr)
sc <- spark_connect(method = "databricks_connect")
```

## 02 - Uploading data from R

1. Load the `nycflights13` library

```{r}

```

2. Use `copy_to()` to upload `planes` to your Spark session. Assign to a variable
called `tbl_planes`

```{r}

```

3. Use `glimpse()` to preview the data 

```{r}

```

4. Use `show_query()` to see how Spark refers to the data you just uploaded

```{r}

```

## 03 - Caching data
*Create a table from elements of another table*

1. Using `tbl()`, create a reference to the "diamonds" table. Assign it to a
variable called `tbl_diamonds`

```{r}

```

2. Select the "cut", "color", "clarity" and "price" fields from `tbl_diamonds` 
and assign to a variable called `tbl_temp`

```{r}

```

3. Use `show_query()` to see the underlying query of `tbl_temp`

```{r}

```

4. Pass `tbl_temp` to `compute()`, and reassign the operation to `tbl_temp`

```{r}

```

5. Use `show_query()` again to see the new underlying query of `tbl_temp`

```{r}

```

6. Preview `tbl_temp`

```{r}
 
```

## 04 - Reading files
*Upload a CSV file that is located inside Databricks, into your Spark session*

1. Use `spark_read_csv()` to upload the airports CSV file to Spark. The `path` 
should be */Volumes/workshops/nycflights/2013/airports.csv*, and `name` should
be `airports_csv`. Assign it to a variable called `tbl_airports`

```{r}
tbl_airports <- spark_read_csv(
  sc = sc,
  name = "airports_csv",
  path = "/Volumes/workshops/nycflights/2013/airports.csv"
  )
```

2. Preview `tbl_airports`

```{r}

```

3. Pass `tbl_airports` to `show_query()` to see the underlying query

```{r}

```

4. Use `sdf_sql()` to access the top 10 rows of "airports_csv" 

```{r}

```


## 05 - "Mapping" files
*Map the flights data without caching the data*

1. Use `spark_read_csv()` to upload the airports CSV file to Spark. The `path` 
should be */Volumes/workshops/nycflights/2013/nycflights.csv*, and `name` should
be `mapped`. **Important**, make sure to set `memory` to false.
Assign it to a variable called `flights_mapped`

```{r}

```

2. Use `glimpse()` to preview the data from `flights_mapped`

```{r}

```
3. Run a quick count by the `carrier` field against `flights_mapped`

```{r}

```

## 06 - Partial cache
*Cache a section of the flights data into Spark*

1. Filter `flights_mapped` to only show flights destined to Orlando (code "ORD")

```{r}

```

2. Assign the previous operation to a variable called `flights_ord`

```{r}

```

3. Pass `flights_ord` to `compute()`, and reassign to `flights_ord`

```{r}

```

4. Preview `flights_ord`

```{r}

```

5. Pass `flights_ord` to `show_query()` to see the new query

```{r}

```

## 07 - End game
*Prepare a working data set using several of the techniques covered in this unit*

1. From `tbl_airports`, select "faa" and "name". Rename the variables to "dest"
and "dest_name" respectively. Assign it to a variable called `dest_airports`

```{r}
dest_airports <- tbl_airports |> 
  select(dest = faa, dest_name = name)
```

2. Preview `dest_airports`

```{r}
dest_airports
```

3. From `tbl_airports`, select "faa" and "name". Rename the variables to "origin"
and "origin_name" respectively. Assign it to a variable called `origin_airports`

```{r}
origin_airports <- tbl_airports |> 
  select(origin = faa, origin_name = name)
```

4. Preview `origin_airports`

```{r}
origin_airports
```

5. Select "tailnum", "dest", "origin", and "distance" from `flights_mapped`. Assign
it to a variable called `flights_select`

```{r}
 
```

6. Preview `flights_select`

```{r}

```

7. Pipe `flights_select` into `head()`

```{r}

```

8. Add a `left_join()` step, after `head()`. Join to the `dest_airports` 
variable, using "dest" as the joining field

```{r}
 
```

9. Add another `left_join()` step. Join to the `origin_airports` 
variable, using "origin" as the joining field

```{r}

```

10. Add another `left_join()` step. Join to the `tbl_planes` 
variable, using "tailnum" as the joining field

```{r}

```

11. Add a `mutate()` step. Use `ifelse()` to modify "dest_name". If "dest_name" 
is NA, then change its value to "Unknown", if not NA, leave alone

```{r}

```

12. Inside the `mutate()` step, add another `ifelse()` to modify "origin_name". 
If "origin_name" is NA, then change its value to "Unknown", if not NA, leave
alone

```{r}

```

13. Inside the `mutate()` step, add another `ifelse()` to modify "tailnum". 
If "tailnum" is NA, then change its value to "Unknown", if not NA, leave
alone

```{r}

```

14. Add a `show_query()` step to see the resulting query

```{r}

```

15. Remove the `head()` step, and run again to see the new query

```{r}

```

16. Assign to a variable called `tbl_prep`, swap the `show_query()` step with
`compute()`

```{r}

```

17. Pipe `tbl_prep` to `show_query()` to see the new query

```{r}

```
