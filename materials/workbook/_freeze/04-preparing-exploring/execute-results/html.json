{
  "hash": "fd07c8561275e17d15b82ce8066030b0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Preparing and Exploring Data\"\nexecute: \n  eval: true\n  freeze: true\n---\n\n\n\n\n## Catch up {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n\ncon <- dbConnect(\n  odbc::databricks(),\n  HTTPPath = \"/sql/1.0/warehouses/300bd24ba12adf8e\"\n)\n\ncustomers <- tbl(con, I(\"samples.tpch.customer\"))\nnation <- tbl(con, I(\"samples.tpch.nation\"))\n```\n:::\n\n\n## Prepare base \n*Building the base variable/query*\n\n1. Load the `orders` table in a variable called `orders`\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders <- tbl(con, I(\"samples.tpch.orders\"))\n```\n:::\n\n\n2. Join `orders` to the `customers` variable (table). Relate them on the\n`o_custkey` and `c_custkey` fields.\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  left_join(customers, by = c(\"o_custkey\" = \"c_custkey\"))\n#> # Source:   SQL [?? x 16]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 10 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>\n```\n:::\n\n\n3. Join the `nation` variable/table to the `orders` and `customers` variables. \nUse the `c_nationkey` and the `n_nationkey` to relate them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  left_join(customers, by = c(\"o_custkey\" = \"c_custkey\")) %>% \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\"))\n#> # Source:   SQL [?? x 19]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 13 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>, n_name <chr>,\n#> #   n_regionkey <int64>, n_comment <chr>\n```\n:::\n\n\n4. Load the resulting code into a variable called `rel_orders`. **We do this \nso to get autocomplete working**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders <- orders %>% \n  left_join(customers, by = c(\"o_custkey\" = \"c_custkey\")) %>% \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\"))\n```\n:::\n\n\n5. Create new columns for the year of the order date, and another for the\nmonth of the order date. Name them `order_year` and `order_month` respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate))\n#> # Source:   SQL [?? x 21]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 15 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>, n_name <chr>,\n#> #   n_regionkey <int64>, n_comment <chr>, order_year <int>, order_month <int>\n```\n:::\n\n\n6. Remove any columns that end in \"comment\", and end in \"key\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n#> # Source:   SQL [?? x 14]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderstatus o_totalprice o_orderdate o_orderpriority o_clerk o_shippriority\n#>    <chr>                <dbl> <date>      <chr>           <chr>            <int>\n#>  1 O                  110800. 1998-05-02  1-URGENT        Clerk#…              0\n#>  2 F                   98993. 1994-12-29  1-URGENT        Clerk#…              0\n#>  3 F                  226256. 1992-03-05  1-URGENT        Clerk#…              0\n#>  4 O                   51906. 1996-06-04  5-LOW           Clerk#…              0\n#>  5 O                  141104. 1995-08-07  3-MEDIUM        Clerk#…              0\n#>  6 O                  157430. 1996-08-14  5-LOW           Clerk#…              0\n#>  7 F                  186262. 1992-10-15  4-NOT SPECIFIED Clerk#…              0\n#>  8 O                  179947. 1997-10-31  2-HIGH          Clerk#…              0\n#>  9 F                  240820. 1992-03-19  4-NOT SPECIFIED Clerk#…              0\n#> 10 O                   42501. 1995-09-04  4-NOT SPECIFIED Clerk#…              0\n#> # ℹ more rows\n#> # ℹ 8 more variables: c_name <chr>, c_address <chr>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, n_name <chr>, order_year <int>,\n#> #   order_month <int>\n```\n:::\n\n\n7. Rename `o_custkey` to `customer`, insert code before the selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  rename(customer = o_custkey) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n#> # Source:   SQL [?? x 15]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    customer o_orderstatus o_totalprice o_orderdate o_orderpriority o_clerk      \n#>     <int64> <chr>                <dbl> <date>      <chr>           <chr>        \n#>  1   540176 O                  110800. 1998-05-02  1-URGENT        Clerk#000004…\n#>  2   299479 F                   98993. 1994-12-29  1-URGENT        Clerk#000001…\n#>  3   395308 F                  226256. 1992-03-05  1-URGENT        Clerk#000004…\n#>  4   687736 O                   51906. 1996-06-04  5-LOW           Clerk#000002…\n#>  5   423847 O                  141104. 1995-08-07  3-MEDIUM        Clerk#000003…\n#>  6    90844 O                  157430. 1996-08-14  5-LOW           Clerk#000004…\n#>  7   432472 F                  186262. 1992-10-15  4-NOT SPECIFIED Clerk#000000…\n#>  8   238820 O                  179947. 1997-10-31  2-HIGH          Clerk#000004…\n#>  9   555686 F                  240820. 1992-03-19  4-NOT SPECIFIED Clerk#000004…\n#> 10    10033 O                   42501. 1995-09-04  4-NOT SPECIFIED Clerk#000003…\n#> # ℹ more rows\n#> # ℹ 9 more variables: o_shippriority <int>, c_name <chr>, c_address <chr>,\n#> #   c_phone <chr>, c_acctbal <dbl>, c_mktsegment <chr>, n_name <chr>,\n#> #   order_year <int>, order_month <int>\n```\n:::\n\n\n8. Load resulting code to a variable called `prep_orders`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders <- rel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  rename(customer = o_custkey) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n```\n:::\n\n\n9. Preview `prep_orders` using `glimpse()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  glimpse()\n#> Rows: ??\n#> Columns: 15\n#> Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> $ customer        <int64> 509198, 540176, 207592, 90848, 105784, 299479, 53179…\n#> $ o_orderstatus   <chr> \"O\", \"O\", \"F\", \"O\", \"O\", \"F\", \"F\", \"F\", \"F\", \"F\", \"O\",…\n#> $ o_totalprice    <dbl> 107104.40, 110800.10, 45904.83, 123597.85, 241150.37, …\n#> $ o_orderdate     <date> 1997-02-12, 1998-05-02, 1992-03-29, 1996-11-14, 1996-…\n#> $ o_orderpriority <chr> \"5-LOW\", \"1-URGENT\", \"5-LOW\", \"3-MEDIUM\", \"2-HIGH\", \"1…\n#> $ o_clerk         <chr> \"Clerk#000003733\", \"Clerk#000004018\", \"Clerk#000000391…\n#> $ o_shippriority  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ c_name          <chr> \"Customer#000509198\", \"Customer#000540176\", \"Customer#…\n#> $ c_address       <chr> \"a,PkLXVPBIQXwjK3w5NItey2Xzp1FYyM\", \"nYdrNb7HJ9oFd24j6…\n#> $ c_phone         <chr> \"10-110-697-3426\", \"11-665-964-8097\", \"11-716-881-4288…\n#> $ c_acctbal       <dbl> 7255.57, 9600.74, 5769.96, 8401.36, 8596.34, 3125.53, …\n#> $ c_mktsegment    <chr> \"MACHINERY\", \"FURNITURE\", \"HOUSEHOLD\", \"FURNITURE\", \"M…\n#> $ n_name          <chr> \"ALGERIA\", \"ARGENTINA\", \"ARGENTINA\", \"IRAN\", \"GERMANY\"…\n#> $ order_year      <int> 1997, 1998, 1992, 1996, 1996, 1994, 1993, 1992, 1994, …\n#> $ order_month     <int> 2, 5, 3, 11, 3, 12, 10, 3, 9, 12, 6, 8, 4, 9, 11, 8, 1…\n```\n:::\n\n\n\n## Answering questions\n*Using the base query to answer more complex questions*\n\n1. What are the top 5 countries for total amount ordered?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(n_name) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   n_name     total_price\n#>   <chr>            <dbl>\n#> 1 IRAQ      45968155784.\n#> 2 INDONESIA 45921526909.\n#> 3 GERMANY   45725194460.\n#> 4 FRANCE    45713656960.\n#> 5 IRAN      45708446851.\n```\n:::\n\n2. What are the top 5 countries for total amount ordered for 1998?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  filter(order_year == 1998) %>% \n  group_by(n_name) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   n_name         total_price\n#>   <chr>                <dbl>\n#> 1 INDONESIA      4139804522.\n#> 2 IRAQ           4135781144.\n#> 3 INDIA          4093598996.\n#> 4 GERMANY        4087438001.\n#> 5 UNITED KINGDOM 4082354151.\n```\n:::\n\n\n3. What has been the top (1) country, in orders, by year?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(n_name, order_year) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  group_by(order_year) %>% \n  filter(total_price == max(total_price))\n#> `summarise()` has grouped output by \"n_name\". You can override using the\n#> `.groups` argument.\n#> Warning: Missing values are always removed in SQL aggregation functions.\n#> Use `na.rm = TRUE` to silence this warning\n#> This warning is displayed once every 8 hours.\n#> # Source:   SQL [7 x 3]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Groups:   order_year\n#>   n_name    order_year total_price\n#>   <chr>          <int>       <dbl>\n#> 1 IRAQ            1992 6989462082.\n#> 2 IRAN            1993 6973453865.\n#> 3 IRAN            1994 7010090121.\n#> 4 FRANCE          1995 6963662249.\n#> 5 IRAQ            1996 7031168753.\n#> 6 INDONESIA       1997 6980529014.\n#> 7 INDONESIA       1998 4139804522.\n```\n:::\n\n4. Who are the top 5 customers by amount ordered?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(customer) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n    ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   customer total_price\n#>    <int64>       <dbl>\n#> 1   721180    7147854.\n#> 2   382414    7139343.\n#> 3   299701    7128451.\n#> 4   321256    7076593.\n#> 5   484219    6920428.\n```\n:::\n\n\n5. What is the country, and market segment, of the top 5 customers by amount ordered?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(customer) %>% \n  summarise(\n    country = first(n_name), \n    segment = first(c_mktsegment),\n    total_price = sum(o_totalprice, na.rm = TRUE)\n    ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 4]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   customer country segment    total_price\n#>    <int64> <chr>   <chr>            <dbl>\n#> 1   721180 ROMANIA BUILDING      7147854.\n#> 2   382414 GERMANY MACHINERY     7139343.\n#> 3   299701 MOROCCO AUTOMOBILE    7128451.\n#> 4   321256 CHINA   HOUSEHOLD     7076593.\n#> 5   484219 INDIA   FURNITURE     6920428.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}