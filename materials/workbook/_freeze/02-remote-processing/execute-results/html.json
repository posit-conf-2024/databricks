{
  "hash": "eab9fd6a2e39ba54667e8b465457d24c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Remote processing\"\nexecute: \n  eval: true\n  freeze: true\n---\n\n\n\n\n## Create a table variable\n\n*Basics to how to point a variable in R to a table or view inside the database*\n\n1. Load the `dplyr`, `DBI` and `dbplyr` libraries\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n```\n:::\n\n\n2. *(Optional)* Open a connection to the database if it's currently closed\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- dbConnect(\n  odbc::databricks(),\n  HTTPPath = \"/sql/1.0/warehouses/300bd24ba12adf8e\"\n)\n```\n:::\n\n\n3. Using `dbGetQuery()` create a query to pull the `diamonds` table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbGetQuery(con, \"select * from diamonds\")\n```\n:::\n\n\n4. Use the `tbl()` to perform the same\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(con, \"diamonds\")\n#> # Source:   table<`diamonds`> [?? x 11]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    `_c0` carat cut       color clarity depth table price     x     y     z\n#>    <int> <dbl> <chr>     <chr> <chr>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#>  1     1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#>  2     2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#>  3     3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#>  4     4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#>  5     5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#>  6     6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#>  7     7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n#>  8     8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n#>  9     9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n#> 10    10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n#> # ℹ more rows\n```\n:::\n\n\n4. Load the reference, not the table data, into a variable\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds <- tbl(con, \"diamonds\")\n```\n:::\n\n\n\n5. Call the variable to see preview the data in the table\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds\n#> # Source:   table<`diamonds`> [?? x 11]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    `_c0` carat cut       color clarity depth table price     x     y     z\n#>    <int> <dbl> <chr>     <chr> <chr>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#>  1     1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#>  2     2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#>  3     3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#>  4     4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#>  5     5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#>  6     6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#>  7     7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n#>  8     8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n#>  9     9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n#> 10    10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n#> # ℹ more rows\n```\n:::\n\n\n6. Add `count()` to easily get the number of rows\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds %>% \n  count()\n#> # Source:   SQL [1 x 1]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>         n\n#>   <int64>\n#> 1   53940\n```\n:::\n\n\n7. Add `cut` as an argument to `count()` to see the count by that field\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds %>% \n  count(cut)\n#> # Source:   SQL [5 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   cut             n\n#>   <chr>     <int64>\n#> 1 Ideal       21551\n#> 2 Premium     13791\n#> 3 Very Good   12082\n#> 4 Good         4906\n#> 5 Fair         1610\n```\n:::\n\n\n8. Add `show_query()` to see the how `dplyr` translates your code to \nSQL \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds %>% \n  count(cut) %>% \n  show_query()\n#> <SQL>\n#> SELECT `cut`, COUNT(*) AS `n`\n#> FROM `diamonds`\n#> GROUP BY `cut`\n```\n:::\n\n## Easily aggretate data\n*An example of how we can use the same code against a local R data frame and a remote table*\n\n1. Using `dplyr`, get the average price for each `cut`, and sort it by the\naverage for `diamonds`, from the `ggplot2` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::diamonds %>% \n  group_by(cut) %>% \n  summarise(avg_price = mean(price, na.rm = TRUE)) %>% \n  arrange(desc(avg_price))\n#> # A tibble: 5 × 2\n#>   cut       avg_price\n#>   <ord>         <dbl>\n#> 1 Premium       4584.\n#> 2 Fair          4359.\n#> 3 Very Good     3982.\n#> 4 Good          3929.\n#> 5 Ideal         3458.\n```\n:::\n\n\n2. Use `tbl_diamonds` to perform the exact same operation \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_diamonds %>% \n  group_by(cut) %>% \n  summarise(avg_price = mean(price, na.rm = TRUE)) %>% \n  arrange(desc(avg_price))\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(avg_price)\n#>   cut       avg_price\n#>   <chr>         <dbl>\n#> 1 Premium       4584.\n#> 2 Fair          4359.\n#> 3 Very Good     3982.\n#> 4 Good          3929.\n#> 5 Ideal         3458.\n```\n:::\n\n\n3. Load code into a variable named `price_by_cut`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice_by_cut <- tbl_diamonds %>% \n  group_by(cut) %>% \n  summarise(avg_price = mean(price, na.rm = TRUE)) %>% \n  arrange(desc(avg_price))\n```\n:::\n\n\n4. Call `price_by_cut` \n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice_by_cut\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(avg_price)\n#>   cut       avg_price\n#>   <chr>         <dbl>\n#> 1 Premium       4584.\n#> 2 Fair          4359.\n#> 3 Very Good     3982.\n#> 4 Good          3929.\n#> 5 Ideal         3458.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}