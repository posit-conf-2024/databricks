{
  "hash": "06e4eafe3e011d7067dd574736da845f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modeling\"\nexecute: \n  eval: true\n  freeze: true\n  warning: false\n---\n\n\n\n\n\n\n## Catch up {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nsc <- spark_connect(method = \"databricks_connect\")\n```\n:::\n\n\n\n\n## Get sample of data\n*Download a sampled data set locally to R*\n\n1. Create a pointer to the `lendingclub` data. It is in the `default` schema, \ninside the `hive_metastore` catalog. And name it `lendingclub_dat`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat <- tbl(sc, I(\"hive_metastore.default.lendingclub\"))\n```\n:::\n\n\n\n\n2. Using `slice_sample()`, download 20K records, and name it `lendingclub_sample`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_sample <- lendingclub_dat |>  \n  slice_sample(n = 2000) |> \n  collect()\n```\n:::\n\n\n\n\n3. Preview the data using the `View()` command\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nView(lendingclub_sample)\n```\n:::\n\n\n\n\n4. Keep only `int_rate`, `term`, `bc_util`, `bc_open_to_buy` and `all_util` \nfields. Remove the percent sign out of `int_rate`, and coerce it to numeric. \nSave resulting table to a new variable called `lendingclub_prep`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_prep <- lendingclub_sample |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  mutate(\n    int_rate = as.numeric(stringr::str_remove(int_rate, \"%\"))\n    )\n```\n:::\n\n\n\n\n5. Preview the data using `glimpse()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(lendingclub_prep)\n#> Rows: 2,000\n#> Columns: 5\n#> $ int_rate       <dbl> 6.83, 11.98, 12.61, 9.43, 15.49, 6.07, 10.41, 9.43, 16.…\n#> $ term           <chr> \" 36 months\", \" 36 months\", \" 36 months\", \" 36 months\",…\n#> $ bc_util        <chr> \"42.2\", \"91.2\", \"84.8\", \"41.4\", \"50.2\", \"6.1\", \"75.2\", …\n#> $ bc_open_to_buy <chr> \"14793\", \"768\", \"2043\", \"4808\", \"6668\", \"31724\", \"10478…\n#> $ all_util       <chr> \"84\", \"57\", \"102\", \"69\", \"33\", \"6\", \"61\", \"79\", \"19\", \"…\n```\n:::\n\n\n\n\n6. Disconnect from Spark\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_disconnect(sc)\n```\n:::\n\n\n\n\n\n## Create model using `tidymodels`\n\n1. Run the following code to create a `workflow` that contains the pre-processing\nsteps, and a linear regression model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\nlendingclub_rec <- recipe(int_rate ~ ., data = lendingclub_prep) |> \n  step_mutate(term = trimws(substr(term, 1,4))) |> \n  step_mutate(across(everything(), as.numeric)) |> \n  step_normalize(all_numeric_predictors()) |>\n  step_impute_mean(all_of(c(\"bc_open_to_buy\", \"bc_util\"))) |>   \n  step_filter(!if_any(everything(), is.na))\n\n\nlendingclub_lr <- linear_reg()\n\nlendingclub_wf <- workflow() |> \n  add_model(lendingclub_lr) |> \n  add_recipe(lendingclub_rec)\n\nlendingclub_wf\n#> ══ Workflow ════════════════════════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: linear_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────────────────────────\n#> 5 Recipe Steps\n#> \n#> • step_mutate()\n#> • step_mutate()\n#> • step_normalize()\n#> • step_impute_mean()\n#> • step_filter()\n#> \n#> ── Model ───────────────────────────────────────────────────────────────────────\n#> Linear Regression Model Specification (regression)\n#> \n#> Computational engine: lm\n```\n:::\n\n\n\n2. Fit the model in the workflow, now in a variable called `lendingclub_wf`, with\nthe `lendingclub_prep` data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_fit <- lendingclub_wf |> \n  fit(data = lendingclub_prep)\n```\n:::\n\n\n\n\n3. Measure the performance of the model using `metrics()`. Make sure to use\n`augment()` to add the predictions first\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_fit |> \n  augment(lendingclub_prep) |> \n  metrics(int_rate, .pred)\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard     6.44   \n#> 2 rsq     standard     0.00336\n#> 3 mae     standard     4.82\n```\n:::\n\n\n\n\n4. Run a histogram over the predictions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\npredict(lendingclub_fit, lendingclub_sample) |> \n  ggplot() +\n  geom_histogram(aes(.pred))\n```\n\n::: {.cell-output-display}\n![](r-udfs-modeling_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n## Using Vetiver\n*Convert the workflow into a `vetiver` model*\n\n1. Load the `vetiver` package\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vetiver)\n```\n:::\n\n\n\n\n2. Convert to Vetiver using `vetiver_model()`. Name the variable `lendingclub_vetiver`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_vetiver <- vetiver_model(lendingclub_fit, \"lendingclub_model\")\n```\n:::\n\n\n\n\n3. Save `lendingclub_vetiver` as \"lendingclub.rds\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(lendingclub_vetiver, \"lendingclub.rds\")\n```\n:::\n\n\n\n\n## Create prediction function\n*Creating a self-contained prediction function that will read the model, and \nthen run the predictions*\n\n1. Create a function that does the following:\n- It has one argument named `x`, which will take the data frame\n- Load the `workflow` and `vetiver` libraries\n- Reads the \"lendingclub.rds\" file\n- Runs the predictions\n- Adds the prediction to `x` \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver <- function(x) {\n  library(workflows)\n  library(vetiver)\n  model <- readRDS(\"lendingclub.rds\")  \n  preds <- predict(model, x)\n  x$pred <- preds[,1][[1]]\n  x\n}\n```\n:::\n\n\n\n\n2. Test the function, use `lendingclub_prep` to confirm it runs as anticipated\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver(lendingclub_prep)\n#> # A tibble: 2,000 × 6\n#>    int_rate term         bc_util bc_open_to_buy all_util  pred\n#>       <dbl> <chr>        <chr>   <chr>          <chr>    <dbl>\n#>  1     6.83 \" 36 months\" 42.2    14793          84        13.7\n#>  2    12.0  \" 36 months\" 91.2    768            57        10.1\n#>  3    12.6  \" 36 months\" 84.8    2043           102       12.3\n#>  4     9.43 \" 36 months\" 41.4    4808           69        11.2\n#>  5    15.5  \" 60 months\" 50.2    6668           33        13.5\n#>  6     6.07 \" 36 months\" 6.1     31724          6         13.2\n#>  7    10.4  \" 36 months\" 75.2    10478          61        12.0\n#>  8     9.43 \" 36 months\" 22.4    19546          79        14.3\n#>  9    16.5  \" 60 months\" 13.9    37031          19        18.4\n#> 10    14.0  \" 36 months\" 79      2355           71        10.9\n#> # ℹ 1,990 more rows\n```\n:::\n\n\n\n\n## Predict in Spark\n*Run the predictions in Spark against the entire data set*\n\n\n1. Add conditional statement that reads the RDS file if it's available locally,\nand if not, read it from: \"/Volumes/workshops/models/vetiver/lendingclub.rds\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver <- function(x) {\n  library(workflows)\n  library(vetiver)\n  if(file.exists(\"lendingclub.rds\")) {\n    model <- readRDS(\"lendingclub.rds\")  \n  } else {\n    model <- readRDS(\"/Volumes/workshops/models/vetiver/lendingclub.rds\")\n  }\n  preds <- predict(model, x)\n  x$pred <- preds[,1][[1]]\n  x\n}\n```\n:::\n\n\n\n\n2. Re-connect to your Spark cluster\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsc <- spark_connect(method = \"databricks_connect\")\n```\n:::\n\n\n\n\n3. Re-create a pointer to the `lendingclub` data. It is in the `default` schema, \ninside the `hive_metastore` catalog. And name it `lendingclub_dat`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat <- tbl(sc, I(\"hive_metastore.default.lendingclub\"))\n```\n:::\n\n\n\n\n4. Select the `int_rate`, `term`, `bc_util`, `bc_open_to_buy`, and `all_util` \nfields from `lendingclub_dat`. And then pass just the top rows (using `head()`)\nto `spark_apply()`. Use the updated `predict_vetiver` to run the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  head() |> \n  spark_apply(predict_vetiver)\n#> # Source:   table<`sparklyr_tmp_table_5ec0b44e_6821_4885_8275_cb245158c394`> [6 x 6]\n#> # Database: spark_connection\n#>   int_rate term         bc_util bc_open_to_buy all_util  pred\n#>   <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#> 1 20.39%   \" 36 months\" 94      133            82        10.8\n#> 2 13.06%   \" 60 months\" 82      10021          70        15.4\n#> 3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#> 4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#> 5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#> 6 16.46%   \" 36 months\" 92.2    380            75        10.5\n```\n:::\n\n\n\n\n5. Add the `columns` specification to the `spark_apply()` call\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  head() |> \n  spark_apply(\n    predict_vetiver, \n    columns = \"int_rate string, term string, bc_util string, bc_open_to_buy string, all_util string, pred double\"\n    )\n#> # Source:   table<`sparklyr_tmp_table_1f8f2594_4000_4af0_b315_8832b768c270`> [6 x 6]\n#> # Database: spark_connection\n#>   int_rate term         bc_util bc_open_to_buy all_util  pred\n#>   <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#> 1 20.39%   \" 36 months\" 94      133            82        10.8\n#> 2 13.06%   \" 60 months\" 82      10021          70        15.4\n#> 3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#> 4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#> 5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#> 6 16.46%   \" 36 months\" 92.2    380            75        10.5\n```\n:::\n\n\n\n6. Append `compute()` to the end of the code, remove `head()`, and save the\nresults into a variable called `lendingclub_predictions`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_predictions <- lendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  spark_apply(\n    predict_vetiver,\n    columns = \"int_rate string, term string, bc_util string, bc_open_to_buy string, all_util string, pred double\"\n    ) |> \n  compute()\n```\n:::\n\n\n\n\n7. Preview the `lendingclub_predictions` table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_predictions\n#> # Source:   table<`table_3b40dc87_958f_4b38_b58a_fd90413d5786`> [?? x 6]\n#> # Database: spark_connection\n#>    int_rate term         bc_util bc_open_to_buy all_util  pred\n#>    <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#>  1 20.39%   \" 36 months\" 94      133            82        10.8\n#>  2 13.06%   \" 60 months\" 82      10021          70        15.4\n#>  3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#>  4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#>  5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#>  6 16.46%   \" 36 months\" 92.2    380            75        10.5\n#>  7 19.42%   \" 60 months\" 21.5    1099           12        11.2\n#>  8 22.90%   \" 60 months\" 36.1    30777          62        18.0\n#>  9 5.31%    \" 36 months\" 54.9    8576           71        11.4\n#> 10 6.83%    \" 36 months\" 12.4    53356          17        15.8\n#> # ℹ more rows\n```\n:::\n",
    "supporting": [
      "r-udfs-modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}