{
  "hash": "06e4eafe3e011d7067dd574736da845f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modeling\"\nexecute: \n  eval: true\n  freeze: true\n  warning: false\n---\n\n\n\n\n## Catch up {.unnumbered}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nsc <- spark_connect(method = \"databricks_connect\")\n```\n:::\n\n\n## Get sample of data\n*Download a sampled data set locally to R*\n\n1. Create a pointer to the `lendingclub` data. It is in the `default` schema, \ninside the `hive_metastore` catalog. And name it `lendingclub_dat`\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat <- tbl(sc, I(\"hive_metastore.default.lendingclub\"))\n```\n:::\n\n\n2. Using `slice_sample()`, download 20K records, and name it `lendingclub_sample`\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_sample <- lendingclub_dat |>  \n  slice_sample(n = 2000) |> \n  collect()\n```\n:::\n\n\n3. Preview the data using the `View()` command\n\n::: {.cell}\n\n```{.r .cell-code}\nView(lendingclub_sample)\n```\n:::\n\n\n4. Keep only `int_rate`, `term`, `bc_util`, `bc_open_to_buy` and `all_util` \nfields. Remove the percent sign out of `int_rate`, and coerce it to numeric. \nSave resulting table to a new variable called `lendingclub_prep`\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_prep <- lendingclub_sample |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  mutate(\n    int_rate = as.numeric(stringr::str_remove(int_rate, \"%\"))\n    )\n```\n:::\n\n\n5. Preview the data using `glimpse()`\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(lendingclub_prep)\n#> Rows: 2,000\n#> Columns: 5\n#> $ int_rate       <dbl> 18.45, 16.46, 7.34, 12.13, 18.45, 11.98, 12.13, 14.03, …\n#> $ term           <chr> \" 36 months\", \" 60 months\", \" 60 months\", \" 60 months\",…\n#> $ bc_util        <chr> \"86.1\", \"54.2\", \"58.5\", \"52.7\", \"96.5\", \"32.6\", NA, \"31…\n#> $ bc_open_to_buy <chr> \"1482\", \"10026\", \"22238\", \"10020\", \"793\", \"4181\", NA, \"…\n#> $ all_util       <chr> \"72\", \"49\", \"56\", \"62\", \"66\", \"104\", \"63\", \"33\", \"63\", …\n```\n:::\n\n\n6. Disconnect from Spark\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_disconnect(sc)\n```\n:::\n\n\n\n## Create model using `tidymodels`\n\n1. Run the following code to create a `workflow` that contains the pre-processing\nsteps, and a linear regression model\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\nlendingclub_rec <- recipe(int_rate ~ ., data = lendingclub_prep) |> \n  step_mutate(term = trimws(substr(term, 1,4))) |> \n  step_mutate(across(everything(), as.numeric)) |> \n  step_normalize(all_numeric_predictors()) |>\n  step_impute_mean(all_of(c(\"bc_open_to_buy\", \"bc_util\"))) |>   \n  step_filter(!if_any(everything(), is.na))\n\n\nlendingclub_lr <- linear_reg()\n\nlendingclub_wf <- workflow() |> \n  add_model(lendingclub_lr) |> \n  add_recipe(lendingclub_rec)\n\nlendingclub_wf\n#> ══ Workflow ════════════════════════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: linear_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────────────────────────\n#> 5 Recipe Steps\n#> \n#> • step_mutate()\n#> • step_mutate()\n#> • step_normalize()\n#> • step_impute_mean()\n#> • step_filter()\n#> \n#> ── Model ───────────────────────────────────────────────────────────────────────\n#> Linear Regression Model Specification (regression)\n#> \n#> Computational engine: lm\n```\n:::\n\n2. Fit the model in the workflow, now in a variable called `lendingclub_wf`, with\nthe `lendingclub_prep` data\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_fit <- lendingclub_wf |> \n  fit(data = lendingclub_prep)\n```\n:::\n\n\n3. Measure the performance of the model using `metrics()`. Make sure to use\n`augment()` to add the predictions first\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_fit |> \n  augment(lendingclub_prep) |> \n  metrics(int_rate, .pred)\n#> # A tibble: 3 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 rmse    standard       6.33 \n#> 2 rsq     standard       0.260\n#> 3 mae     standard       4.79\n```\n:::\n\n\n4. Run a histogram over the predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\npredict(lendingclub_fit, lendingclub_sample) |> \n  ggplot() +\n  geom_histogram(aes(.pred))\n```\n\n::: {.cell-output-display}\n![](r-udfs-modeling_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Using Vetiver\n*Convert the workflow into a `vetiver` model*\n\n1. Load the `vetiver` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vetiver)\n```\n:::\n\n\n2. Convert to Vetiver using `vetiver_model()`. Name the variable `lendingclub_vetiver`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_vetiver <- vetiver_model(lendingclub_fit, \"lendingclub_model\")\n```\n:::\n\n\n3. Save `lendingclub_vetiver` as \"lendingclub.rds\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(lendingclub_vetiver, \"lendingclub.rds\")\n```\n:::\n\n\n## Create prediction function\n*Creating a self-contained prediction function that will read the model, and \nthen run the predictions*\n\n1. Create a function that does the following:\n- It has one argument named `x`, which will take the data frame\n- Load the `workflow` and `vetiver` libraries\n- Reads the \"lendingclub.rds\" file\n- Runs the predictions\n- Adds the prediction to `x` \n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver <- function(x) {\n  library(workflows)\n  library(vetiver)\n  model <- readRDS(\"lendingclub.rds\")  \n  preds <- predict(model, x)\n  x$pred <- preds[,1][[1]]\n  x\n}\n```\n:::\n\n\n2. Test the function, use `lendingclub_prep` to confirm it runs as anticipated\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver(lendingclub_prep)\n#> # A tibble: 2,000 × 6\n#>    int_rate term         bc_util bc_open_to_buy all_util   pred\n#>       <dbl> <chr>        <chr>   <chr>          <chr>     <dbl>\n#>  1    18.4  \" 36 months\" 86.1    1482           72        10.8 \n#>  2    16.5  \" 60 months\" 54.2    10026          49        12.0 \n#>  3     7.34 \" 60 months\" 58.5    22238          56        10.3 \n#>  4    12.1  \" 60 months\" 52.7    10020          62        12.7 \n#>  5    18.4  \" 36 months\" 96.5    793            66        10.6 \n#>  6    12.0  \" 36 months\" 32.6    4181           104       11.7 \n#>  7    12.1  \" 36 months\" <NA>    <NA>           63        11.5 \n#>  8    14.0  \" 60 months\" 31      24137          33         8.66\n#>  9    19.4  \" 60 months\" 63.7    8159           63        13.1 \n#> 10     7.34 \" 36 months\" 15.4    108512         30       -10.4 \n#> # ℹ 1,990 more rows\n```\n:::\n\n\n## Predict in Spark\n*Run the predictions in Spark against the entire data set*\n\n\n1. Add conditional statement that reads the RDS file if it's available locally,\nand if not, read it from: \"/Volumes/workshops/models/vetiver/lendingclub.rds\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_vetiver <- function(x) {\n  library(workflows)\n  library(vetiver)\n  if(file.exists(\"lendingclub.rds\")) {\n    model <- readRDS(\"lendingclub.rds\")  \n  } else {\n    model <- readRDS(\"/Volumes/workshops/models/vetiver/lendingclub.rds\")\n  }\n  preds <- predict(model, x)\n  x$pred <- preds[,1][[1]]\n  x\n}\n```\n:::\n\n\n2. Re-connect to your Spark cluster\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsc <- spark_connect(method = \"databricks_connect\")\n```\n:::\n\n\n3. Re-create a pointer to the `lendingclub` data. It is in the `default` schema, \ninside the `hive_metastore` catalog. And name it `lendingclub_dat`\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat <- tbl(sc, I(\"hive_metastore.default.lendingclub\"))\n```\n:::\n\n\n4. Select the `int_rate`, `term`, `bc_util`, `bc_open_to_buy`, and `all_util` \nfields from `lendingclub_dat`. And then pass just the top rows (using `head()`)\nto `spark_apply()`. Use the updated `predict_vetiver` to run the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  head() |> \n  spark_apply(predict_vetiver)\n#> # Source:   table<`sparklyr_tmp_table_ff7892f2_9999_43e4_acea_6be661ae8c6d`> [6 x 6]\n#> # Database: spark_connection\n#>   int_rate term         bc_util bc_open_to_buy all_util  pred\n#>   <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#> 1 20.39%   \" 36 months\" 94      133            82        10.8\n#> 2 13.06%   \" 60 months\" 82      10021          70        15.4\n#> 3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#> 4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#> 5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#> 6 16.46%   \" 36 months\" 92.2    380            75        10.5\n```\n:::\n\n\n5. Add the `columns` specification to the `spark_apply()` call\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  head() |> \n  spark_apply(\n    predict_vetiver, \n    columns = \"int_rate string, term string, bc_util string, bc_open_to_buy string, all_util string, pred double\"\n    )\n#> # Source:   table<`sparklyr_tmp_table_5d45f5bd_81e9_481b_ac4f_e50b19b8a21e`> [6 x 6]\n#> # Database: spark_connection\n#>   int_rate term         bc_util bc_open_to_buy all_util  pred\n#>   <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#> 1 20.39%   \" 36 months\" 94      133            82        10.8\n#> 2 13.06%   \" 60 months\" 82      10021          70        15.4\n#> 3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#> 4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#> 5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#> 6 16.46%   \" 36 months\" 92.2    380            75        10.5\n```\n:::\n\n6. Append `compute()` to the end of the code, remove `head()`, and save the\nresults into a variable called `lendingclub_predictions`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_predictions <- lendingclub_dat |> \n  select(int_rate, term, bc_util, bc_open_to_buy, all_util) |> \n  spark_apply(\n    predict_vetiver,\n    columns = \"int_rate string, term string, bc_util string, bc_open_to_buy string, all_util string, pred double\"\n    ) |> \n  compute()\n```\n:::\n\n\n7. Preview the `lendingclub_predictions` table\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlendingclub_predictions\n#> # Source:   table<`table_8d8d3049_fb9a_43fe_a973_2b59960974ab`> [?? x 6]\n#> # Database: spark_connection\n#>    int_rate term         bc_util bc_open_to_buy all_util  pred\n#>    <chr>    <chr>        <chr>   <chr>          <chr>    <dbl>\n#>  1 20.39%   \" 36 months\" 94      133            82        10.8\n#>  2 13.06%   \" 60 months\" 82      10021          70        15.4\n#>  3 10.56%   \" 60 months\" 34.5    41570          54        19.3\n#>  4 6.83%    \" 36 months\" 7.9     23119          47        12.4\n#>  5 17.47%   \" 60 months\" 62.1    11686          57        15.0\n#>  6 16.46%   \" 36 months\" 92.2    380            75        10.5\n#>  7 19.42%   \" 60 months\" 21.5    1099           12        11.2\n#>  8 22.90%   \" 60 months\" 36.1    30777          62        18.0\n#>  9 5.31%    \" 36 months\" 54.9    8576           71        11.4\n#> 10 6.83%    \" 36 months\" 12.4    53356          17        15.8\n#> # ℹ more rows\n```\n:::\n",
    "supporting": [
      "r-udfs-modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}