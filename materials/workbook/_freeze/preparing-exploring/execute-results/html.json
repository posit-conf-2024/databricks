{
  "hash": "8ef5ac11a2065a19a50a57c30329e43e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Preparing and exploring Data\"\nexecute: \n  eval: true\n  freeze: true\n---\n\n\n\n\n\n\n## Catch up {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n\ncon <- dbConnect(\n  odbc::databricks(),\n  HTTPPath = \"/sql/1.0/warehouses/300bd24ba12adf8e\"\n)\n\ntbl_diamonds <- tbl(con, \"diamonds\")\n```\n:::\n\n\n\n\n## Selecting variables\n*Simple strategies to order, and reduce, data to work with*\n\n1. Load the `customer` table to a variable called `customer` \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer <- tbl(con, I(\"samples.tpch.customer\"))\n```\n:::\n\n\n\n2. Select all columns that end with \"key\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer |> \n  select(ends_with(\"key\"))\n#> # Source:   SQL [?? x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    c_custkey c_nationkey\n#>      <int64>     <int64>\n#>  1    412445          21\n#>  2    412446          20\n#>  3    412447           7\n#>  4    412448           6\n#>  5    412449          14\n#>  6    412450          20\n#>  7    412451          20\n#>  8    412452          10\n#>  9    412453          21\n#> 10    412454           9\n#> # ℹ more rows\n```\n:::\n\n\n\n\n3. Move all columns that end with \"key\" to the front\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer |> \n  select(ends_with(\"key\"), everything())\n#> # Source:   SQL [?? x 8]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    c_custkey c_nationkey c_name         c_address c_phone c_acctbal c_mktsegment\n#>      <int64>     <int64> <chr>          <chr>     <chr>       <dbl> <chr>       \n#>  1    412445          21 Customer#0004… \"0QAB3Oj… 31-421…     5358. BUILDING    \n#>  2    412446          20 Customer#0004… \"5u8MSby… 30-487…     9442. MACHINERY   \n#>  3    412447           7 Customer#0004… \"HC4ZT62… 17-797…     7869. AUTOMOBILE  \n#>  4    412448           6 Customer#0004… \"hJok1MM… 16-541…     6061. MACHINERY   \n#>  5    412449          14 Customer#0004… \"zAt1nZN… 24-710…     4974. HOUSEHOLD   \n#>  6    412450          20 Customer#0004… \"fUD6IoG… 30-293…     4406. BUILDING    \n#>  7    412451          20 Customer#0004… \"W2Ge0Qd… 30-590…     2290. BUILDING    \n#>  8    412452          10 Customer#0004… \"Ij4xiPI… 20-492…     3427. AUTOMOBILE  \n#>  9    412453          21 Customer#0004… \"4DmSxDP… 31-480…     4592. MACHINERY   \n#> 10    412454           9 Customer#0004… \"ZQfKDMU… 19-898…     2036. FURNITURE   \n#> # ℹ more rows\n#> # ℹ 1 more variable: c_comment <chr>\n```\n:::\n\n\n\n\n4. Select all columns that **do not** end with \"key\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer |> \n  select(-ends_with(\"key\"))\n#> # Source:   SQL [?? x 6]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    c_name             c_address         c_phone c_acctbal c_mktsegment c_comment\n#>    <chr>              <chr>             <chr>       <dbl> <chr>        <chr>    \n#>  1 Customer#000412445 \"0QAB3OjYnbP6mA0… 31-421…     5358. BUILDING     \"arefull…\n#>  2 Customer#000412446 \"5u8MSbyiC7J,7Pu… 30-487…     9442. MACHINERY    \"sleep a…\n#>  3 Customer#000412447 \"HC4ZT62gKPgrjr … 17-797…     7869. AUTOMOBILE   \"aggle b…\n#>  4 Customer#000412448 \"hJok1MMrDgH\"     16-541…     6061. MACHINERY    \"ly sile…\n#>  5 Customer#000412449 \"zAt1nZNG01gOhIq… 24-710…     4974. HOUSEHOLD    \"refully…\n#>  6 Customer#000412450 \"fUD6IoGdtF\"      30-293…     4406. BUILDING     \"refully…\n#>  7 Customer#000412451 \"W2Ge0Qd8adH\"     30-590…     2290. BUILDING     \"slow as…\n#>  8 Customer#000412452 \"Ij4xiPIeNEP1uR5… 20-492…     3427. AUTOMOBILE   \"sleep s…\n#>  9 Customer#000412453 \"4DmSxDPMmfidKQB… 31-480…     4592. MACHINERY    \" agains…\n#> 10 Customer#000412454 \"ZQfKDMUyEfn\"     19-898…     2036. FURNITURE    \" quickl…\n#> # ℹ more rows\n```\n:::\n\n\n\n\n\n## Join to tables\n**Using left_join() to relate two tables**\n\n1. Load the `nation` table into a variable called the same\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnation <- tbl(con, I(\"samples.tpch.nation\"))\n```\n:::\n\n\n\n\n2. Use `left_join` to relate `customer` with `nation` using the nation key \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer |> \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\"))\n#> # Source:   SQL [?? x 11]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    c_custkey c_name         c_address c_nationkey c_phone c_acctbal c_mktsegment\n#>      <int64> <chr>          <chr>         <int64> <chr>       <dbl> <chr>       \n#>  1    412445 Customer#0004… \"0QAB3Oj…          21 31-421…     5358. BUILDING    \n#>  2    412446 Customer#0004… \"5u8MSby…          20 30-487…     9442. MACHINERY   \n#>  3    412447 Customer#0004… \"HC4ZT62…           7 17-797…     7869. AUTOMOBILE  \n#>  4    412448 Customer#0004… \"hJok1MM…           6 16-541…     6061. MACHINERY   \n#>  5    412449 Customer#0004… \"zAt1nZN…          14 24-710…     4974. HOUSEHOLD   \n#>  6    412450 Customer#0004… \"fUD6IoG…          20 30-293…     4406. BUILDING    \n#>  7    412451 Customer#0004… \"W2Ge0Qd…          20 30-590…     2290. BUILDING    \n#>  8    412452 Customer#0004… \"Ij4xiPI…          10 20-492…     3427. AUTOMOBILE  \n#>  9    412453 Customer#0004… \"4DmSxDP…          21 31-480…     4592. MACHINERY   \n#> 10    412454 Customer#0004… \"ZQfKDMU…           9 19-898…     2036. FURNITURE   \n#> # ℹ more rows\n#> # ℹ 4 more variables: c_comment <chr>, n_name <chr>, n_regionkey <int64>,\n#> #   n_comment <chr>\n```\n:::\n\n\n\n\n3. What are the 5 countries with the most customers?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer |> \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\")) |> \n  count(n_name, sort = TRUE) |> \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(n)\n#>   n_name          n\n#>   <chr>     <int64>\n#> 1 INDONESIA   30401\n#> 2 IRAN        30257\n#> 3 INDIA       30234\n#> 4 IRAQ        30232\n#> 5 ETHIOPIA    30201\n```\n:::\n\n\n\n\n## Prepare base \n*Building the base variable/query*\n\n1. Load the `orders` table in a variable called `orders`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders <- tbl(con, I(\"samples.tpch.orders\"))\n```\n:::\n\n\n\n\n2. Join `orders` to the `customer` variable (table). Relate them on the\n`o_custkey` and `c_custkey` fields.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  left_join(customer, by = c(\"o_custkey\" = \"c_custkey\"))\n#> # Source:   SQL [?? x 16]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 10 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>\n```\n:::\n\n\n\n\n3. Join the `nation` variable/table to the `orders` and `customer` variables. \nUse the `c_nationkey` and the `n_nationkey` to relate them.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  left_join(customer, by = c(\"o_custkey\" = \"c_custkey\")) %>% \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\"))\n#> # Source:   SQL [?? x 19]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 13 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>, n_name <chr>,\n#> #   n_regionkey <int64>, n_comment <chr>\n```\n:::\n\n\n\n\n4. Load the resulting code into a variable called `rel_orders`. **We do this \nso to get autocomplete working**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders <- orders %>% \n  left_join(customer, by = c(\"o_custkey\" = \"c_custkey\")) %>% \n  left_join(nation, by = c(\"c_nationkey\" = \"n_nationkey\"))\n```\n:::\n\n\n\n\n5. Create new columns for the year of the order date, and another for the\nmonth of the order date. Name them `order_year` and `order_month` respectively.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate))\n#> # Source:   SQL [?? x 21]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderkey o_custkey o_orderstatus o_totalprice o_orderdate o_orderpriority\n#>       <int64>   <int64> <chr>                <dbl> <date>      <chr>          \n#>  1    5611654    540176 O                  110800. 1998-05-02  1-URGENT       \n#>  2   11396198    299479 F                   98993. 1994-12-29  1-URGENT       \n#>  3    5611651    395308 F                  226256. 1992-03-05  1-URGENT       \n#>  4    5611649    687736 O                   51906. 1996-06-04  5-LOW          \n#>  5    5611652    423847 O                  141104. 1995-08-07  3-MEDIUM       \n#>  6    5611653     90844 O                  157430. 1996-08-14  5-LOW          \n#>  7   11396196    432472 F                  186262. 1992-10-15  4-NOT SPECIFIED\n#>  8   13710946    238820 O                  179947. 1997-10-31  2-HIGH         \n#>  9    5611681    555686 F                  240820. 1992-03-19  4-NOT SPECIFIED\n#> 10   13710948     10033 O                   42501. 1995-09-04  4-NOT SPECIFIED\n#> # ℹ more rows\n#> # ℹ 15 more variables: o_clerk <chr>, o_shippriority <int>, o_comment <chr>,\n#> #   c_name <chr>, c_address <chr>, c_nationkey <int64>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, c_comment <chr>, n_name <chr>,\n#> #   n_regionkey <int64>, n_comment <chr>, order_year <int>, order_month <int>\n```\n:::\n\n\n\n\n6. Remove any columns that end in \"comment\", and end in \"key\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n#> # Source:   SQL [?? x 14]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    o_orderstatus o_totalprice o_orderdate o_orderpriority o_clerk o_shippriority\n#>    <chr>                <dbl> <date>      <chr>           <chr>            <int>\n#>  1 O                  110800. 1998-05-02  1-URGENT        Clerk#…              0\n#>  2 F                   98993. 1994-12-29  1-URGENT        Clerk#…              0\n#>  3 F                  226256. 1992-03-05  1-URGENT        Clerk#…              0\n#>  4 O                   51906. 1996-06-04  5-LOW           Clerk#…              0\n#>  5 O                  141104. 1995-08-07  3-MEDIUM        Clerk#…              0\n#>  6 O                  157430. 1996-08-14  5-LOW           Clerk#…              0\n#>  7 F                  186262. 1992-10-15  4-NOT SPECIFIED Clerk#…              0\n#>  8 O                  179947. 1997-10-31  2-HIGH          Clerk#…              0\n#>  9 F                  240820. 1992-03-19  4-NOT SPECIFIED Clerk#…              0\n#> 10 O                   42501. 1995-09-04  4-NOT SPECIFIED Clerk#…              0\n#> # ℹ more rows\n#> # ℹ 8 more variables: c_name <chr>, c_address <chr>, c_phone <chr>,\n#> #   c_acctbal <dbl>, c_mktsegment <chr>, n_name <chr>, order_year <int>,\n#> #   order_month <int>\n```\n:::\n\n\n\n\n7. Rename `o_custkey` to `customer`, insert code before the selection\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  rename(customer = o_custkey) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n#> # Source:   SQL [?? x 15]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>    customer o_orderstatus o_totalprice o_orderdate o_orderpriority o_clerk      \n#>     <int64> <chr>                <dbl> <date>      <chr>           <chr>        \n#>  1   540176 O                  110800. 1998-05-02  1-URGENT        Clerk#000004…\n#>  2   299479 F                   98993. 1994-12-29  1-URGENT        Clerk#000001…\n#>  3   395308 F                  226256. 1992-03-05  1-URGENT        Clerk#000004…\n#>  4   687736 O                   51906. 1996-06-04  5-LOW           Clerk#000002…\n#>  5   423847 O                  141104. 1995-08-07  3-MEDIUM        Clerk#000003…\n#>  6    90844 O                  157430. 1996-08-14  5-LOW           Clerk#000004…\n#>  7   432472 F                  186262. 1992-10-15  4-NOT SPECIFIED Clerk#000000…\n#>  8   238820 O                  179947. 1997-10-31  2-HIGH          Clerk#000004…\n#>  9   555686 F                  240820. 1992-03-19  4-NOT SPECIFIED Clerk#000004…\n#> 10    10033 O                   42501. 1995-09-04  4-NOT SPECIFIED Clerk#000003…\n#> # ℹ more rows\n#> # ℹ 9 more variables: o_shippriority <int>, c_name <chr>, c_address <chr>,\n#> #   c_phone <chr>, c_acctbal <dbl>, c_mktsegment <chr>, n_name <chr>,\n#> #   order_year <int>, order_month <int>\n```\n:::\n\n\n\n\n8. Load resulting code to a variable called `prep_orders`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders <- rel_orders %>% \n  mutate(order_year = year(o_orderdate), order_month = month(o_orderdate)) %>% \n  rename(customer = o_custkey) %>% \n  select(-ends_with(\"comment\"), -ends_with(\"key\")) \n```\n:::\n\n\n\n\n9. Preview `prep_orders` using `glimpse()`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  glimpse()\n#> Rows: ??\n#> Columns: 15\n#> Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> $ customer        <int64> 509198, 540176, 207592, 90848, 105784, 299479, 53179…\n#> $ o_orderstatus   <chr> \"O\", \"O\", \"F\", \"O\", \"O\", \"F\", \"F\", \"F\", \"F\", \"F\", \"O\",…\n#> $ o_totalprice    <dbl> 107104.40, 110800.10, 45904.83, 123597.85, 241150.37, …\n#> $ o_orderdate     <date> 1997-02-12, 1998-05-02, 1992-03-29, 1996-11-14, 1996-…\n#> $ o_orderpriority <chr> \"5-LOW\", \"1-URGENT\", \"5-LOW\", \"3-MEDIUM\", \"2-HIGH\", \"1…\n#> $ o_clerk         <chr> \"Clerk#000003733\", \"Clerk#000004018\", \"Clerk#000000391…\n#> $ o_shippriority  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ c_name          <chr> \"Customer#000509198\", \"Customer#000540176\", \"Customer#…\n#> $ c_address       <chr> \"a,PkLXVPBIQXwjK3w5NItey2Xzp1FYyM\", \"nYdrNb7HJ9oFd24j6…\n#> $ c_phone         <chr> \"10-110-697-3426\", \"11-665-964-8097\", \"11-716-881-4288…\n#> $ c_acctbal       <dbl> 7255.57, 9600.74, 5769.96, 8401.36, 8596.34, 3125.53, …\n#> $ c_mktsegment    <chr> \"MACHINERY\", \"FURNITURE\", \"HOUSEHOLD\", \"FURNITURE\", \"M…\n#> $ n_name          <chr> \"ALGERIA\", \"ARGENTINA\", \"ARGENTINA\", \"IRAN\", \"GERMANY\"…\n#> $ order_year      <int> 1997, 1998, 1992, 1996, 1996, 1994, 1993, 1992, 1994, …\n#> $ order_month     <int> 2, 5, 3, 11, 3, 12, 10, 3, 9, 12, 6, 8, 4, 9, 11, 8, 1…\n```\n:::\n\n\n\n\n\n## Answering questions\n*Using the base query to answer more complex questions*\n\n1. What are the top 5 countries for total amount ordered?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(n_name) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   n_name     total_price\n#>   <chr>            <dbl>\n#> 1 IRAQ      45968155784.\n#> 2 INDONESIA 45921526909.\n#> 3 GERMANY   45725194460.\n#> 4 FRANCE    45713656960.\n#> 5 IRAN      45708446851.\n```\n:::\n\n\n\n2. What are the top 5 countries for total amount ordered for 1998?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  filter(order_year == 1998) %>% \n  group_by(n_name) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   n_name         total_price\n#>   <chr>                <dbl>\n#> 1 INDONESIA      4139804522.\n#> 2 IRAQ           4135781144.\n#> 3 INDIA          4093598996.\n#> 4 GERMANY        4087438001.\n#> 5 UNITED KINGDOM 4082354151.\n```\n:::\n\n\n\n\n3. What has been the top (1) country, in orders, by year?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(n_name, order_year) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n  ) %>% \n  group_by(order_year) %>% \n  filter(total_price == max(total_price))\n#> `summarise()` has grouped output by \"n_name\". You can override using the\n#> `.groups` argument.\n#> Warning: Missing values are always removed in SQL aggregation functions.\n#> Use `na.rm = TRUE` to silence this warning\n#> This warning is displayed once every 8 hours.\n#> # Source:   SQL [7 x 3]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Groups:   order_year\n#>   n_name    order_year total_price\n#>   <chr>          <int>       <dbl>\n#> 1 IRAQ            1992 6989462082.\n#> 2 IRAN            1993 6973453865.\n#> 3 IRAN            1994 7010090121.\n#> 4 FRANCE          1995 6963662249.\n#> 5 IRAQ            1996 7031168753.\n#> 6 INDONESIA       1997 6980529014.\n#> 7 INDONESIA       1998 4139804522.\n```\n:::\n\n\n\n4. Who are the top 5 customers by amount ordered?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(customer) %>% \n  summarise(\n    total_price = sum(o_totalprice, na.rm = TRUE)\n    ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 2]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   customer total_price\n#>    <int64>       <dbl>\n#> 1   721180    7147854.\n#> 2   382414    7139343.\n#> 3   299701    7128451.\n#> 4   321256    7076593.\n#> 5   484219    6920428.\n```\n:::\n\n\n\n\n5. What is the country, and market segment, of the top 5 customers by amount ordered?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprep_orders %>% \n  group_by(customer) %>% \n  summarise(\n    country = first(n_name), \n    segment = first(c_mktsegment),\n    total_price = sum(o_totalprice, na.rm = TRUE)\n    ) %>% \n  arrange(desc(total_price)) %>% \n  head(5)\n#> # Source:     SQL [5 x 4]\n#> # Database:   Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#> # Ordered by: desc(total_price)\n#>   customer country segment    total_price\n#>    <int64> <chr>   <chr>            <dbl>\n#> 1   721180 ROMANIA BUILDING      7147854.\n#> 2   382414 GERMANY MACHINERY     7139343.\n#> 3   299701 MOROCCO AUTOMOBILE    7128451.\n#> 4   321256 CHINA   HOUSEHOLD     7076593.\n#> 5   484219 INDIA   FURNITURE     6920428.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}