{
  "hash": "6a4bfec48672fcf09d801f2d313b4d0d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Working with LLMs in Databricks\"\nexecute: \n  eval: true\n  freeze: true\n  warning: false\n---\n\n\n\n\n\n\n## Catch up {.unnumbered}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n\ncon <- dbConnect(\n  odbc::databricks(),\n  HTTPPath = \"/sql/1.0/warehouses/300bd24ba12adf8e\"\n)\n```\n:::\n\n\n\n\n## Accessing AI functions\n*Use the sentiment classification function*\n\n1. Create a quick review table using the following code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreviews <- tribble(\n  ~name,     ~review, \n  \"adam\",    \"This is the best toaster I have ever bought\",\n  \"berry\",   \"Toaster arrived broken, waiting for replancement\",\n  \"charles\", \"The washing machine is as advertised, can't wait to use it\",\n  \"dan\",     \"Not sure how to feel about this tevelision, nice brightness but bad definition\"\n) |> \n  select(review)\n```\n:::\n\n\n\n\n2. Copy the `reviews` data frame to your SQL session. Assign it to a variable\ncalled `tbl_reviews`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_reviews <- copy_to(con, reviews, overwrite = TRUE)\n```\n:::\n\n\n\n\n3. Create a new field called \"sentiment\", use `ai_analyze_sentiment()` to \nanalyze the \"review\" field\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_reviews |> \n  mutate(sentiment = ai_analyze_sentiment(review))\n#> # Source:   SQL [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                               sentiment\n#>   <chr>                                                                <chr>    \n#> 1 This is the best toaster I have ever bought                          positive \n#> 2 Toaster arrived broken, waiting for replancement                     negative \n#> 3 The washing machine is as advertised, cant wait to use it            positive \n#> 4 Not sure how to feel about this tevelision, nice brightness but bad… mixed\n```\n:::\n\n\n\n\n## Specify array\n*Using array() to run the classification function*\n\n1. Use `ai_classify()` to find out if we need to follow up with customer. The \ntwo options should be: 'order complete', and 'need follow up'. Use `array()`\nas if you would be using the `c()` function. Name the new field \"follow_up\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_reviews |> \n  mutate(\n    follow_up = ai_classify(review, array(\"order complete\", \"need follow up\"))\n    )\n#> # Source:   SQL [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                               follow_up\n#>   <chr>                                                                <chr>    \n#> 1 This is the best toaster I have ever bought                          order co…\n#> 2 Toaster arrived broken, waiting for replancement                     need fol…\n#> 3 The washing machine is as advertised, cant wait to use it            order co…\n#> 4 Not sure how to feel about this tevelision, nice brightness but bad… need fol…\n```\n:::\n\n\n\n\n2. Add a step that keeps only those orders that need follow up\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_reviews |> \n  mutate(\n    follow_up = ai_classify(review, array(\"order complete\", \"need follow up\"))\n    ) |> \n  filter(follow_up == \"need follow up\")\n#> # Source:   SQL [2 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                               follow_up\n#>   <chr>                                                                <chr>    \n#> 1 Toaster arrived broken, waiting for replancement                     need fol…\n#> 2 Not sure how to feel about this tevelision, nice brightness but bad… need fol…\n```\n:::\n\n\n\n\n## Process complex output\n*Working STRUCT output from an 'ai' function*\n\n1. Use `ai_extract()` to pull the type of product being referred to in the\nreview. Pass 'product' as the extract argument, and pass it inside an `array()`\ncall. Name the new field \"product\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_reviews |> \n  mutate(product = ai_extract(review, array(\"product\")))\n#> # Source:   SQL [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                                 product\n#>   <chr>                                                                  <chr>  \n#> 1 This is the best toaster I have ever bought                            \"{\\\"pr…\n#> 2 Toaster arrived broken, waiting for replancement                       \"{\\\"pr…\n#> 3 The washing machine is as advertised, cant wait to use it              \"{\\\"pr…\n#> 4 Not sure how to feel about this tevelision, nice brightness but bad d… \"{\\\"pr…\n```\n:::\n\n\n\n\n\n2. Append a `compute()` step, and assign to a new variable called `tbl_review`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review <- tbl_reviews |> \n  mutate(product = ai_extract(review, array(\"product\"))) |> \n  compute()\n```\n:::\n\n\n\n\n3. Preview `tbl_review`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review \n#> # Source:   table<`dbplyr_BPEjpTJvMJ`> [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                                 product\n#>   <chr>                                                                  <chr>  \n#> 1 This is the best toaster I have ever bought                            \"{\\\"pr…\n#> 2 Toaster arrived broken, waiting for replancement                       \"{\\\"pr…\n#> 3 The washing machine is as advertised, cant wait to use it              \"{\\\"pr…\n#> 4 Not sure how to feel about this tevelision, nice brightness but bad d… \"{\\\"pr…\n```\n:::\n\n\n\n\n4. Pass `tbl_review` to `show_query()` to confirm that it is pulling from a \nnew temporary table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review |> \n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM `dbplyr_BPEjpTJvMJ`\n```\n:::\n\n\n\n\n5. Coerce \"product\" to a character\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review |> \n  mutate(product = as.character(product))\n#> # Source:   SQL [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                                 product\n#>   <chr>                                                                  <chr>  \n#> 1 This is the best toaster I have ever bought                            {toast…\n#> 2 Toaster arrived broken, waiting for replancement                       {Toast…\n#> 3 The washing machine is as advertised, cant wait to use it              {washi…\n#> 4 Not sure how to feel about this tevelision, nice brightness but bad d… {telev…\n```\n:::\n\n\n\n\n6. Wrap the `as.character()` call, inside a `tolower()` call\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review |> \n  mutate(product = tolower(as.character(product)))\n#> # Source:   SQL [4 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   review                                                                 product\n#>   <chr>                                                                  <chr>  \n#> 1 This is the best toaster I have ever bought                            {toast…\n#> 2 Toaster arrived broken, waiting for replancement                       {toast…\n#> 3 The washing machine is as advertised, cant wait to use it              {washi…\n#> 4 Not sure how to feel about this tevelision, nice brightness but bad d… {telev…\n```\n:::\n\n\n\n\n7. Add a count step, that breaks down the reviews by product\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl_review |> \n  mutate(product = tolower(as.character(product))) |> \n  count(product)\n#> # Source:   SQL [3 x 2]\n#> # Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n#>   product                 n\n#>   <chr>             <int64>\n#> 1 {washing machine}       1\n#> 2 {toaster}               2\n#> 3 {television}            1\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}