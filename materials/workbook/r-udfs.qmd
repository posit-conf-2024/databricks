---
title: "Intro to R UDFs"
execute: 
  eval: true
  freeze: true
  warning: false
---

```{r, setup}
#| include: false

library(dplyr)
library(dbplyr)
library(sparklyr)
library(tidymodels)
library(tidyverse)
```

## Catch up {.unnumbered}

```{r}
library(sparklyr)
library(dplyr)
sc <- spark_connect(method = "databricks_connect")
```

## Simple operations
*Trying out very simple operation to become familiar with the process*

1. Use `copy_to()` to send `mtcars` to the cluster. Load it to a variable called
`tbl_mtcars`

```{r}
tbl_mtcars <- copy_to(sc, mtcars)
```

2. Pipe `tbl_mtcars` to `spark_apply()`. Use `nrow` as the function to run

```{r}
tbl_mtcars |> 
  spark_apply(nrow)
```

3. Switch the function to use in `spark_apply()` to `dim`. Notice how it
returns more rows, because coercing the size 2 vector creates a 2 row data frame

```{r}
tbl_mtcars |> 
  spark_apply(dim)
```


