{
  "hash": "4ae8c14e217a6d9f09170024214a16eb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"dplyr basics\"\nexecute: \n  eval: true\n  freeze: true\n---\n\n\n\n\n## Create a table variable\n\n*Basics to how to point a variable in R to a table or view inside the database*\n\n\n1. Load the `dplyr`, `DBI` and `dbplyr` libraries\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n```\n:::\n\n\n2. *(Optional)* Open a connection to the database if it's currently closed\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- dbConnect(odbc::odbc(), \"warehouse\")\n```\n:::\n\n\n\n3. Use the `tbl()` and `in_catalog()` functions to create a reference to a table\n\n::: {.cell}\n\n```{.r .cell-code}\ntbl(con, in_catalog(\"samples\", \"tpch\", \"customer\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   table<`samples`.`tpch`.`customer`> [?? x 8]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n   c_custkey c_name         c_address c_nationkey c_phone c_acctbal c_mktsegment\n     <int64> <chr>          <chr>         <int64> <chr>       <dbl> <chr>       \n 1    412445 Customer#0004… \"0QAB3Oj…          21 31-421…     5358. BUILDING    \n 2    412446 Customer#0004… \"5u8MSby…          20 30-487…     9442. MACHINERY   \n 3    412447 Customer#0004… \"HC4ZT62…           7 17-797…     7869. AUTOMOBILE  \n 4    412448 Customer#0004… \"hJok1MM…           6 16-541…     6061. MACHINERY   \n 5    412449 Customer#0004… \"zAt1nZN…          14 24-710…     4974. HOUSEHOLD   \n 6    412450 Customer#0004… \"fUD6IoG…          20 30-293…     4406. BUILDING    \n 7    412451 Customer#0004… \"W2Ge0Qd…          20 30-590…     2290. BUILDING    \n 8    412452 Customer#0004… \"Ij4xiPI…          10 20-492…     3427. AUTOMOBILE  \n 9    412453 Customer#0004… \"4DmSxDP…          21 31-480…     4592. MACHINERY   \n10    412454 Customer#0004… \"ZQfKDMU…           9 19-898…     2036. FURNITURE   \n# ℹ more rows\n# ℹ 1 more variable: c_comment <chr>\n```\n\n\n:::\n:::\n\n\n4. Load the reference, not the table data, into a variable\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers <- tbl(con, in_catalog(\"samples\", \"tpch\", \"customer\"))\n```\n:::\n\n\n\n5. Call the variable to see preview the data in the table\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   table<`samples`.`tpch`.`customer`> [?? x 8]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n   c_custkey c_name         c_address c_nationkey c_phone c_acctbal c_mktsegment\n     <int64> <chr>          <chr>         <int64> <chr>       <dbl> <chr>       \n 1    412445 Customer#0004… \"0QAB3Oj…          21 31-421…     5358. BUILDING    \n 2    412446 Customer#0004… \"5u8MSby…          20 30-487…     9442. MACHINERY   \n 3    412447 Customer#0004… \"HC4ZT62…           7 17-797…     7869. AUTOMOBILE  \n 4    412448 Customer#0004… \"hJok1MM…           6 16-541…     6061. MACHINERY   \n 5    412449 Customer#0004… \"zAt1nZN…          14 24-710…     4974. HOUSEHOLD   \n 6    412450 Customer#0004… \"fUD6IoG…          20 30-293…     4406. BUILDING    \n 7    412451 Customer#0004… \"W2Ge0Qd…          20 30-590…     2290. BUILDING    \n 8    412452 Customer#0004… \"Ij4xiPI…          10 20-492…     3427. AUTOMOBILE  \n 9    412453 Customer#0004… \"4DmSxDP…          21 31-480…     4592. MACHINERY   \n10    412454 Customer#0004… \"ZQfKDMU…           9 19-898…     2036. FURNITURE   \n# ℹ more rows\n# ℹ 1 more variable: c_comment <chr>\n```\n\n\n:::\n:::\n\n\n6. Set up the pointers to the other of the tables\n\n::: {.cell}\n\n```{.r .cell-code}\norders <- tbl(con, in_catalog(\"samples\", \"tpch\", \"orders\"))\nregions <- tbl(con, in_catalog(\"samples\", \"tpch\", \"region\"))\n```\n:::\n\n\n## Under the hood \n*Use `show_query()` to preview the SQL statement that will be sent to the database*\n\n1. SQL statement that actually runs when we ran `customers` as a command\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_query(customers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT *\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n2. Easily view the resulting query by adding `show_query()` in another piped command\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT *\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n3. Insert `head()` in between the two statements to see how the SQL changes\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  head() %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*\nFROM `samples`.`tpch`.`customer`\nLIMIT 6\n```\n\n\n:::\n:::\n\n\n4. Use `sql_render()` and `simulate_mssql()` to see how the SQL statement changes from vendor to vendor\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  head() %>%\n  sql_render(con = simulate_mssql()) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL> SELECT TOP 6 `customer`.*\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n5. Use `explain()` to explore the query plan\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>% \n  head() %>% \n  explain()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*\nFROM `samples`.`tpch`.`customer`\nLIMIT 6\n\n<PLAN>\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               plan\n1 == Physical Plan ==\\nCollectLimit 6\\n+- ColumnarToRow\\n   +- PhotonResultStage\\n      +- PhotonScan parquet samples.tpch.customer[c_custkey#6368L,c_name#6369,c_address#6370,c_nationkey#6371L,c_phone#6372,c_acctbal#6373,c_mktsegment#6374,c_comment#6375] DataFilters: [], DictionaryFilters: [], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba..., RequiredDataFilters: []\\n\\n\\n== Photon Explanation ==\\nPhoton does not fully support the query because:\\n\\t\\tUnsupported node: CollectLimit 6.\\n\\nReference node:\\n\\tCollectLimit 6\\n\n```\n\n\n:::\n:::\n\n\n## Un-translated R commands\n*Review of how `dbplyr` handles R commands that have not been translated into a like-SQL command*\n\n1. Preview how `Sys.time()` is translated\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = Sys.time()) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*, Sys.time() AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n2. Use Databricks's native commands, in this case `current_date()` \n(https://docs.databricks.com/en/sql/language-manual/functions/current_date.html)\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = current_date()) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*, current_date() AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n3. Run the `dplyr` code to confirm it works\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = current_date()) %>%\n  select(today) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [6 x 1]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n  today     \n  <date>    \n1 2024-05-09\n2 2024-05-09\n3 2024-05-09\n4 2024-05-09\n5 2024-05-09\n6 2024-05-09\n```\n\n\n:::\n:::\n\n\n## Using bang-bang\n*Intro on passing unevaluated code to a dplyr verb*\n\n1. Preview how `Sys.time()` is translated\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = Sys.time()) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*, Sys.time() AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n2. Preview how `Sys.time()` is translated when prefixing `!!`\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = !! Sys.time()) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*, '2024-05-09T15:37:15Z' AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n3. Preview how `Sys.time()` is translated when prefixing `!!`\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = !!Sys.time()) %>%\n  select(today) %>%\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [6 x 1]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n  today               \n  <chr>               \n1 2024-05-09T15:37:15Z\n2 2024-05-09T15:37:15Z\n3 2024-05-09T15:37:15Z\n4 2024-05-09T15:37:15Z\n5 2024-05-09T15:37:15Z\n6 2024-05-09T15:37:15Z\n```\n\n\n:::\n:::\n\n\n## knitr SQL engine\n\n1. Copy the result of the latest `show_query()` exercise\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  mutate(today = !!Sys.time()) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `customer`.*, '2024-05-09T15:37:15Z' AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n:::\n:::\n\n\n2. Paste the result in this SQL chunk\n\n::: {.cell}\n\n```{.sql .cell-code}\nSELECT `customer`.*, '2024-05-09T13:37:11Z' AS `today`\nFROM `samples`.`tpch`.`customer`\n```\n\n\n<div class=\"knitsql-table\">\n\n\nTable: Displaying records 1 - 10\n\n|c_custkey |c_name             |c_address                                | c_nationkey|c_phone         | c_acctbal|c_mktsegment |c_comment                                                                                                |today                |\n|:---------|:------------------|:----------------------------------------|-----------:|:---------------|---------:|:------------|:--------------------------------------------------------------------------------------------------------|:--------------------|\n|412445    |Customer#000412445 |0QAB3OjYnbP6mA0B,kgf                     |          21|31-421-403-4333 |   5358.33|BUILDING     |arefully blithely regular epi                                                                            |2024-05-09T13:37:11Z |\n|412446    |Customer#000412446 |5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg       |          20|30-487-949-7942 |   9441.59|MACHINERY    |sleep according to the fluffily even forges. fluffily careful packages after the ironic, silent deposi   |2024-05-09T13:37:11Z |\n|412447    |Customer#000412447 |HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO        |           7|17-797-466-6308 |   7868.75|AUTOMOBILE   |aggle blithely among the carefully express excus                                                         |2024-05-09T13:37:11Z |\n|412448    |Customer#000412448 |hJok1MMrDgH                              |           6|16-541-510-4964 |   6060.98|MACHINERY    |ly silent requests boost slyly. express courts sleep according to the fluf                               |2024-05-09T13:37:11Z |\n|412449    |Customer#000412449 |zAt1nZNG01gOhIqgyDtDa S,Y0VSofZJs1dd     |          14|24-710-983-5536 |   4973.84|HOUSEHOLD    |refully final theodolites. final, slow excuses sleep quickly! quickly ironic idea                        |2024-05-09T13:37:11Z |\n|412450    |Customer#000412450 |fUD6IoGdtF                               |          20|30-293-696-5047 |   4406.28|BUILDING     |refully final dolphins after the carefully bold packages sleep quickly express deposits. fluffily        |2024-05-09T13:37:11Z |\n|412451    |Customer#000412451 |W2Ge0Qd8adH                              |          20|30-590-724-6711 |   2290.38|BUILDING     |slow asymptotes will are carefully final packages. slyly regular fox                                     |2024-05-09T13:37:11Z |\n|412452    |Customer#000412452 |Ij4xiPIeNEP1uR5p7H                       |          10|20-492-590-3363 |   3426.64|AUTOMOBILE   |sleep slyly after the sometimes even ideas. slyly express theodolites dazzle furiously ironic dependenci |2024-05-09T13:37:11Z |\n|412453    |Customer#000412453 |4DmSxDPMmfidKQB3W50FIzkjZESEW3LPgLBuQbic |          21|31-480-724-9665 |   4592.14|MACHINERY    |against the slyly regular requests-- pending, pending accounts boost quic                                |2024-05-09T13:37:11Z |\n|412454    |Customer#000412454 |ZQfKDMUyEfn                              |           9|19-898-261-2669 |   2035.91|FURNITURE    |quickly. blithely special theodolites about the excus                                                    |2024-05-09T13:37:11Z |\n\n</div>\n:::\n\n\n\n## Basic aggregation\n*A couple of `dplyr` commands that run in-database*\n\n1. How many records are in the **airport** table?\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers  %>%\n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [1 x 1]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n        n\n  <int64>\n1  750000\n```\n\n\n:::\n:::\n\n\n2. What is the average character length of the airport codes? How many characters is the longest and the shortest airport name?\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomers %>%\n  summarise(\n    avg_customer_balance = mean(c_acctbal, na.rm = TRUE),\n    max_customer_balance = max(c_acctbal, na.rm = TRUE),\n    min_customer_balance = min(c_acctbal, na.rm = TRUE),\n    total_records = n()\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [1 x 4]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n  avg_customer_balance max_customer_balance min_customer_balance total_records\n                 <dbl>                <dbl>                <dbl>       <int64>\n1                4501.               10000.               -1000.        750000\n```\n\n\n:::\n:::\n\n\n3. How many records are in the **orders** table?\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>%\n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [1 x 1]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n        n\n  <int64>\n1 7500000\n```\n\n\n:::\n:::\n\n\n4. What is the highest total price of an order?\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>%\n  summarise(x = max(o_totalprice, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Source:   SQL [1 x 1]\n# Database: Spark SQL 3.1.1[token@Spark SQL/hive_metastore]\n        x\n    <dbl>\n1 569370.\n```\n\n\n:::\n:::\n\n\n5. What is the SQL statement sent in exercise 4?\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>%\n  summarise(x = max(o_totalprice, na.rm = TRUE)) %>%\n  show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT MAX(`o_totalprice`) AS `x`\nFROM `samples`.`tpch`.`orders`\n```\n\n\n:::\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}