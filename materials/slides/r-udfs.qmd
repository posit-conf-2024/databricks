---
format: 
  revealjs:
    width: 1600
    height: 920
    max-scale: 1
    min-scale: 1
    smaller: true
    transition: fade
    background-transition: fade
    theme: theme.scss
    code-line-numbers: false
    menu: true
    code-block-height: 640px
    slide-number: true
engine: knitr
---

```{r}
#| include: false
unit_no <- 6
```

# {background-image="assets/background/content-slide.svg" background-size="1700px" background-color="#2a7070"}

:::{.content-slide-title}
Unit `r unit_no`
:::

:::{.content-slide}
Intro to <br/> 
R UDF
:::

## [What is an UDF?]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

<br/>

:::{.custom}
:::{.incremental1}
- Stands for **"User Defined Function"**
- Enables operations not built-in Spark
- Can be written in Scala, Python, or R
:::
:::

## [Ok, but what does that mean?!]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

## [Ok, but what does that mean?!]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

[
<br/><br/><br/>
We can run R code *inside* Spark! ðŸŽ‰ ðŸŽ‰
]{style="font-size:100px;line-height:0.5;font-weight:600;color:#579297;"}

## [But first... parallel processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="25%"}
:::
:::{.column width="75%"}
[Spark partitions the data logically]{style="font-size:60px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/r-udfs/spark-1.png){.absolute top="200" left="400" width="400"}
![](assets/r-udfs/spark-2.png){.absolute top="190" left="900" width="400"}
![](assets/r-udfs/spark-3.png){.absolute top="390" left="900" width="400"}
![](assets/r-udfs/spark-4.png){.absolute top="590" left="900" width="400"}

## [Parallel processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="20%"}
:::
:::{.column width="70%"}
[Each node gets one, or several partitions]{style="font-size:60px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/r-udfs/spark-6.png){.absolute top="250" left="320" width="200"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="100" width="200"}
![](assets/r-udfs/spark-3.png){.absolute top="420" left="100" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="250" left="1320" width="200"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="1100" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="420" left="1100" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="1180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="500" left="770" width="200"}
![](assets/r-udfs/spark-3.png){.absolute top="550" left="550" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="670" left="550" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="800" left="660" width="200"}

## [Parallel processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="5%"}
:::
:::{.column width="95%"}
[The cluster runs jobs that process each partition in parallel]{style="font-size:55px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/r-udfs/spark-6.png){.absolute top="250" left="320" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="293" left="90" width="220"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="100" width="200"}
![](assets/r-udfs/spark-3.png){.absolute top="420" left="100" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="250" left="1320" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="413" left="1090" width="220"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="1100" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="420" left="1100" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="1180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="500" left="770" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="542" left="540" width="220"}
![](assets/r-udfs/spark-3.png){.absolute top="550" left="550" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="670" left="550" width="200"}
![](assets/r-udfs/spark.svg){.absolute top="800" left="660" width="200"}

## [Parallel processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="10%"}
:::
:::{.column width="90%"}
[Your R function runs on each partition independently]{style="font-size:55px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/r-udfs/spark-6.png){.absolute top="250" left="320" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="293" left="90" width="220"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="100" width="200"}
![](assets/r-udfs/spark-3.png){.absolute top="420" left="100" width="200"}
![](assets/r-udfs/r-logo.png){.absolute top="310" left="150" width="100"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="250" left="1320" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="413" left="1090" width="220"}
![](assets/r-udfs/spark-2.png){.absolute top="300" left="1100" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="420" left="1100" width="200"}
![](assets/r-udfs/r-logo.png){.absolute top="430" left="1150" width="100"}
![](assets/r-udfs/spark.svg){.absolute top="550" left="1180" width="200"}

![](assets/r-udfs/spark-6.png){.absolute top="500" left="770" width="200"}
![](assets/r-udfs/spark-5.png){.absolute top="542" left="540" width="220"}
![](assets/r-udfs/spark-3.png){.absolute top="550" left="550" width="200"}
![](assets/r-udfs/spark-4.png){.absolute top="670" left="550" width="200"}
![](assets/r-udfs/r-logo.png){.absolute top="560" left="590" width="100"}
![](assets/r-udfs/spark.svg){.absolute top="800" left="660" width="200"}

## [Parallel processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="1%"}
:::
:::{.column width="99%"}
[Results are appended, and returned to user as a single table]{style="font-size:60px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/r-udfs/spark-2.png){.absolute top="210" left="600" width="400"}
![](assets/r-udfs/spark-3.png){.absolute top="400" left="600" width="400"}
![](assets/r-udfs/spark-4.png){.absolute top="590" left="600" width="400"}

## [Accessing in R]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

:::{.columns}
:::{.column width="42%"}

:::{.incremental1}
:::: {style="text-align: left; float:left;"}
[
`spark_apply()` enables acces to the R runtime installed in the cluster. 
The R function will run over each individual partition.
]{style="color:#666; font-weight:500;font-size:52px;"} 
<br><br>
[
In this case, 4 partitions of 8 rows each. The results from each partition are 
merged in a single table.
]{style="color:#666; font-weight:500;font-size:52px;"} 


:::
:::

:::
:::{.column width="58%"}
:::{.code-slim-35}
```r
tbl_mtcars <- copy_to(sc, mtcars)

tbl_mtcars |> 
  spark_apply(nrow)
#> # Source:   table<`sparklyr_tmp_table_d83f7f26`> [4 x 1]
#> # Database: spark_connection
#>       x
#>   <dbl>
#> 1     8
#> 2     8
#> 3     8
#> 4     8
```
:::
:::
:::

## {background-image="assets/background/boxed-green.svg" background-size="1700px" background-color="#799857"}

:::{.green-slide}
Exercise `r unit_no`.1
:::

## [Mapping by groups]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

:::{.columns}
:::{.column width="42%"}

:::{.incremental1}
:::: {style="text-align: left; float:left;"}
[
Use `group_by` to override the partitions, and use a column as the way to 
divide the data.
<br><br>
]{style="color:#666; font-weight:500;font-size:52px;"} 

:::
:::

:::
:::{.column width="58%"}
:::{.code-slim-35}
```r
tbl_mtcars <- copy_to(sc, mtcars)

tbl_mtcars |> 
  spark_apply(nrow, group_by = "am")
#> # Source:   table<`sparklyr_tmp_table_c30d3aba_515f`> [2 x 2]
#> # Database: spark_connection
#>      am     x
#>   <dbl> <dbl>
#> 1     0    19
#> 2     1    13
```
:::
:::
:::

## {background-image="assets/background/boxed-green.svg" background-size="1700px" background-color="#799857"}

:::{.green-slide}
Exercise `r unit_no`.2
:::


## [Custom functions]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/r-udfs/expectations.png){.absolute top="250" left="50" width="1800"}

:::{.columns}
:::{.column width="4%"}
:::
:::{.column width="95%"}
[Create custom R functions that expects and outputs tables]{style="font-size:58px;line-height:0.5;font-weight:600;color:#579297;"}
:::
:::

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}


## {background-image="assets/background/boxed-green.svg" background-size="1700px" background-color="#799857"}

:::{.green-slide}
Exercise `r unit_no`.3
:::

## [Databricks Connect]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

The Databricks Spark cluster has R, and Python, packages pre-installed for
your convenience. The list and versions vary by [DBR version](https://docs.databricks.com/en/release-notes/runtime/15.3.html#installed-r-libraries). 

## [Python UDFs]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/r-udfs/python-udfs.png){.absolute top="270" left="50" width="1800"}

:::{.columns}
:::{.column width="7%"}
:::
:::{.column width="91%"}
[Python code is packaged and sent to Databricks which runs it]{style="font-size:54px;line-height:1;font-weight:400;color:#666;"}
:::
:::

## [R UDFs]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

![](assets/r-udfs/r-udfs.png){.absolute top="230" left="50" width="1800"}

:::{.columns}
:::{.column width="13%"}
:::
:::{.column width="80%"}
[`sparklyr` inserts your R code inside a Python script]{style="font-size:54px;line-height:1;font-weight:400;color:#666;"}
:::
:::

:::{.footer}
https://spark.posit.co/deployment/databricks-connect-udfs.html
:::