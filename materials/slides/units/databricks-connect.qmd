---
engine: knitr
---

```{r}
#| include: false
if(!("no_databricks" %in% ls())) no_databricks <- 1
```

# {background-image="assets/background/content-slide.svg" background-size="1700px" background-color="#2a7070"}

:::{.content-slide-title}
Unit `r no_databricks`
:::

:::{.content-slide}
Databricks <br/> Connect
:::

## [Databricks Connect]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="50%"}

:::{.custom2}
:::{.incremental1}
- Spark Connect, offers **true** remote connectivity
- Uses **gRPC** to as the communication interface
- **Databricks Connect 'v2'** is based on Spark Connect (DBR 13+)
:::
:::

:::
:::{.column width="45%"}
:::
:::

![](assets/databricks-connect/grpc){.absolute top="264" left="900" width="670"}


## [Databricks Connect]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="37%"}

:::{.custom2}
:::{.incremental1}
- `databricks-connect` integrates with gRPC, by wrapping `pyspark`
- `pyspark` is the most developed **Spark Connect** interface
:::
:::

:::
:::{.column width="60%"}
:::
:::

![](assets/databricks-connect/python.png){.absolute top="264" left="572" width="998"}

## [Databricks Connect]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

:::{.columns}
:::{.column width="4%"}
:::
:::{.column width="96%"}
[`sparklyr` integrates with `databricks-connect` via `reticulate`]{style="font-size:54px;line-height:1;font-weight:400;color:#666;"}
:::
:::



![](assets/databricks-connect/db-connect.png){.absolute top="200" left="70" width="1500"}

## [Why not just use 'reticulate'?]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

[**sparklyr** extends functionality and user experience:]{style="font-size:65px;line-height:1;font-weight:400;color:#666;"}


:::{.columns}
:::{.column width="45%"}

:::{.custom2}
:::{.incremental1}
  - `dplyr` back-end
  - `DBI` back-end
  - R UDFs 
  - **RStudio**, and **Positron**, Connections Pane integration
:::
:::

:::
:::{.column width="55%"}
:::{.code-slim-35}
```r
library(sparklyr) 
sc <- spark_connect(method = "databricks_connect") 

trips <- tbl(sc, I("samples.nyctaxi.trips")) 

trips |>  
  group_by(pickup_zip) |> 
  summarise( 
    count = n(), 
    avg_distance = mean(trip_distance) 
    )
```
:::
:::
:::

## [Getting started]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

:::{.columns}
:::{.column width="42%"}

:::{.custom2}
:::{.incremental1}
- Python 3.10+ 
- A Python environment with `databricks-connect` and its dependencies
- `pysparklyr` extension
:::
:::

:::
:::{.column width="58%"}
:::{.code-slim-35}
```r
install.packages("pysparklyr")
library(sparklyr) 
sc <- spark_connect(
  cluster_id = "1026-175310-7cpsh3g8",
  method = "databricks_connect"
  )
```
:::
:::
:::

## [Getting started]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

![](assets/posit-databricks.png){.absolute top="-10" left="1430" width="180"}

:::{.columns}
:::{.column width="42%"}

:::{.incremental1}
:::: {style="text-align: left; float:left;"}
[
`pysparklyr` automatically, checks for, and installs the needed Python packages. <br/>
<br/>
Once you confirm, it will create a new virtual environment, and installs the 
packages.
]{style="color:#666; font-weight:500;font-size:52px;"} 
:::
:::

:::
:::{.column width="58%"}
:::{.code-slim-35}
```r
install.packages("pysparklyr")
library(sparklyr) 
sc <- spark_connect(
  cluster_id = "1026-175310-7cpsh3g8",
  method = "databricks_connect"
  )
#> ! Retrieving version from cluster '1026-175310-7cpsh3g8'
#> Cluster version: '14.1' 
#> ! No viable Python Environment was identified for 
#> Databricks Connect version 14.1 
#> Do you wish to install Databricks Connect version 14.1? 
#> 1: Yes
#> 2: No
#> 3: Cancel
```
:::
:::
:::


## {background-image="assets/background/boxed-green.svg" background-size="1700px" background-color="#799857"}

:::{.green-slide}
Exercise `r no_databricks`.1
:::

## [Data processing]{style="color:#666;"} {background-image="assets/background/slide-light.svg" background-size="1700px" background-color="white"}

:::{.columns}
:::{.column width="20%"}
:::
:::{.column width="70%"}
[Data is read and processed. Results go to R.]{style="font-size:54px;line-height:1;font-weight:400;color:#666;"}
:::
:::

![](assets/databricks-connect/warehouse-r.png){.absolute top="200" left="220" width="1100"}

